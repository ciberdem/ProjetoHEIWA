# Pipeline de Pr√©-processamento de Texto

O **Pipeline de Pr√©-processamento de Texto** tem como objetivo padronizar e preparar dados textuais para aplica√ß√µes em **Processamento de Linguagem Natural (PLN)**, aplicando uma sequ√™ncia de transforma√ß√µes que facilitam o uso de modelos de aprendizado de m√°quina.

---
# Conte√∫do

- [Como Utilizar](#como-utilizar)
  - [Depend√™ncias](dependencias)
    - [Instala√ß√£o das Depend√™ncias](instala√ß√£o-de-depend√™ncias)
  - [Executando o Pipeline](executando-o-pipeline)
    - [Exemplo de Uso](exemplo-de-uso)
- [Funcionalidades](#funcionalidades)
  - [Par√¢metros para Ativar/Desativar Etapas](par√¢metros-para-ativar/desativar-etapas)
- [Fun√ß√µes do Pipeline](fun√ß√µes-do-peipeline)
- [Estrutura de Sa√≠da](estrutura-de-sa√≠da)
- [Detalhes do Pr√©-processamento de Texto](#detalhes-do-pr√©-processamento-de-texto)

---

# Como Utilizar

## Depend√™ncias
Antes de executar o pipeline, certifique-se de ter as seguintes bibliotecas instaladas:

- demoji: https://pypi.org/project/demoji/
- pandas: https://pypi.org/project/pandas/
- nltk: https://pypi.org/project/nltk/
- enelvo: https://pypi.org/project/enelvo/
- unidecode: https://pypi.org/project/Unidecode/

### Instala√ß√£o das Depend√™ncias

Para instalar todas as depend√™ncias, utilize o arquivo requirements.txt. Com o arquivo pronto, basta executar o comando:

```python
pip install -r /path/to/requirements.txt
```

Ap√≥s a instala√ß√£o das bibliotecas, √© necess√°rio baixar alguns conte√∫dos adicionais para do NLTK para que o pipelone funcione corretamente. 

```python
import nltk

nltk.download('punkt')
nltk.download('stopwords')
nltk.download('punkt_tab')
```

## Executando o Pipeline

- **Arquivo de entrada**: O pipeline aceita arquivos nos formatos `.csv` ou `.json`. O caminho do arquivo de entrada e o nome da coluna que cont√©m o texto a ser processado devem ser fornecidos.
- **Processamento**: O pipeline pode ser executado por meio da fun√ß√£o pipeline. Ela carrega o arquivo, aplica o pr√©-processamento e exporta o resultado.

- **OBS**: Todas as etapas de pr√©-processamento s√£o **opcionais** e podem ser ativadas ou desativadas conforme necess√°rio ao chamar a fun√ß√£o `pipeline`. Cada etapa √© controlada por um par√¢metro booleano (`True` para ativar e `False` para desativar).


### Exemplo de Uso

```python
from pipeline_de_limpeza import pipeline

caminho_arquivo = 'dados.csv'  # ou 'dados.json'
coluna = 'texto'
formato = 'json'

# Executando o pipeline
pipeline(caminho_arquivo, coluna, formato)
```

# Funcionalidades

O pipeline realiza as seguintes etapas principais:

1. **Normaliza√ß√£o de Texto**  
   Convers√£o para letras min√∫sculas, remo√ß√£o de acentua√ß√£o, pontua√ß√£o e espa√ßos extras.

2. **Substitui√ß√£o de G√≠rias e Abrevia√ß√µes**  
   Converte termos informais para suas formas padr√£o, garantindo maior consist√™ncia sem√¢ntica.

3. **Tokeniza√ß√£o**  
   Separa o texto em palavras (tokens), facilitando o tratamento e an√°lise.

4. **Remo√ß√£o de Stopwords**  
   Elimina palavras sem relev√¢ncia sem√¢ntica, como artigos e preposi√ß√µes.

5. **Reconstru√ß√£o do Texto**  
   Retorna o texto processado de forma limpa e padronizada.

Para desativar etapas espec√≠ficas, basta definir o par√¢metro desejado como `False` ao chamar a fun√ß√£o `pipeline`. Por exemplo, para desativar a normaliza√ß√£o e a remo√ß√£o de URLs:

```python
from pipeline import pipeline

# Executa o pipeline sem normalizar o texto e sem remover URLs
pipeline('dados.csv', 'texto', formato='json', normalizar=False, remover_urls=False)
```


### Par√¢metros para Ativar/Desativar Etapas

- `substituir_emojis` (padr√£o: `True`): Substitui emojis por r√≥tulos sentimentais.
- `substituir_users` (padr√£o: `True`): Remove men√ß√µes a usu√°rios (exemplo: @usuario).
- `normalizar` (padr√£o: `True`): Aplica a normaliza√ß√£o ao texto para padronizar varia√ß√µes informais utilizando ferramenta enelvo.
- `remover_urls` (padr√£o: `True`): Remove URLs do texto.
- `converter_ascii` (padr√£o: `True`): Converte caracteres especiais para ASCII.
- `remover_pontuacao` (padr√£o: `True`): Remove pontua√ß√µes n√£o associadas a n√∫meros.


# Fun√ß√µes do Pipeline
## 1.substituir_girias(texto, dicionario_de_girias)
Substitui g√≠rias em um texto com base em um dicion√°rio, garantindo a substitui√ß√£o apenas de palavras inteiras e ignorando mai√∫sculas/min√∫sculas

**Par√¢metros**:
`texto (str)`: Texto no qual os emojis ser√£o substitu√≠dos.
`dicionario_de_girias (dict)`: Dicion√°rio Python onde cada chave √© uma g√≠ria e cada valor √© o significado ‚Äúnormalizado‚Äù dela.

**Retorno**:
Texto com as g√≠rias substituidas por seu significado normaliizado. 

```python
def substituir_girias(texto, dicionario_de_girias):
    """
    Substitui g√≠rias em um texto com base em um dicion√°rio, garantindo a substitui√ß√£o
    apenas de palavras inteiras e ignorando mai√∫sculas/min√∫sculas.
    """
    sorted_girias = sorted(dicionario_de_girias.keys(), key=len, reverse=True)
    texto_processado = str(texto)
    for giria in sorted_girias:
        significado = dicionario_de_girias[giria]
        padrao = r'\b' + re.escape(giria) + r'\b'
        texto_processado = re.sub(padrao, significado, texto_processado, flags=re.IGNORECASE)
    return texto_processado
```



## 2. `substitui_emoji(text)`
Substitui os emojis por r√≥tulos sentimentais (emojipositivo, emojinegativo, emojineutro) ou descri√ß√µes Unicode.

**Par√¢metros**:
`text (str)`: Texto no qual os emojis ser√£o substitu√≠dos.

**Retorno**:
Texto com emojis substitu√≠dos.

```python
def substitui_emoji(text):
    """
    Substitui emojis em um texto por r√≥tulos de sentimento ou descri√ß√µes de emojis.

    Par√¢metros:
    text (str): O texto no qual os emojis ser√£o substitu√≠dos.

    Retorna:
    str: O texto com os emojis substitu√≠dos por r√≥tulos de sentimentos ou descri√ß√µes Unicode.
    """
    for emoji, label in emoji_list.items():
        text = text.replace(emoji, label)
    dem = demoji.findall(text)
    for item, value in dem.items():
        text = text.replace(item, f" {value.replace(' ', '')}")
    return text
```



## 3. `preprocess(texto, substituir_users=True, remover_urls=True, ...)`
Aplica o pipeline de pr√©-processamento ao texto com diversas etapas opcionais, como normaliza√ß√£o, remo√ß√£o de URLs e emojis.

**Par√¢metros**:

-`texto (pd.Series)`: S√©rie Pandas contendo os textos a serem processados.
-`substituir_users (bool)`: Substitui men√ß√µes a usu√°rios no formato @usuario por <user>, evitando que o Enelvo modifique esses elementos.
-`remover_urls (bool)`: Substitui links e URLs por <hyperlink> antes da normaliza√ß√£o, garantindo consist√™ncia. (Padr√£o: True)
-`normalizar (bool)`: Aplica a normaliza√ß√£o ao texto utilizando o Enelvo, que corrige g√≠rias, abrevia√ß√µes e erros ortogr√°ficos, mantendo os placeholders <user> e <hyperlink>.
-`substituir_emojis (bool)`: Substitui emojis por r√≥tulos sentimentais ou descri√ß√µes textuais.
-`converter_ascii (bool)`: Converte caracteres especiais (acentos, cedilhas, etc.) para caracteres ASCII simples.
-`remover_pontuacao (bool)`: Remove pontua√ß√µes e s√≠mbolos n√£o associados a n√∫meros, hashtags ou men√ß√µes.
-`tokenizar_texto (bool)`: Tokeniza o texto em palavras, remove stopwords e retorna o texto limpo.

**Retorno**:
S√©rie Pandas com o texto pr√©-processado.

```python
def preprocess(texto, normalizar=True, substituir_emojis=True, substituir_users=True, remover_urls=True, converter_ascii=True, remover_pontuacao=True, tokenizar_texto=True):
    """
    Aplica o pipeline de pr√©-processamento ao texto fornecido.

    Par√¢metros:
    texto (pd.Series): Uma s√©rie pandas contendo os textos a serem processados.
    normalizar (bool): Normaliza o texto usando o enelvo. Padr√£o: True.
    substituir_emojis (bool): Substitui emojis por r√≥tulos de sentimentos. Padr√£o: True.
    substituir_users (bool): Remove men√ß√µes a usu√°rios no formato @usuario. Padr√£o: True.
    remover_urls (bool): Remove URLs do texto. Padr√£o: True.
    converter_ascii (bool): Converte caracteres especiais para ASCII. Padr√£o: True.
    remover_pontuacao (bool): Remove pontua√ß√µes desnecess√°rias. Padr√£o: True.
    tokenizar_texto(bool): Tokeniza o texto e remove as stopwords. Padr√£o: True.

    Retorna:
    pd.Series: Uma s√©rie pandas com o texto pr√©-processado.
    """
    if substituir_users:
        texto = texto.str.replace(r'@\w+', '<user>', regex=True)
        
    if remover_urls:
        texto = texto.apply(lambda x: re.sub(r'http\S+', '<hyperlink>', x))

    texto = texto.apply(lambda x: substituir_girias(x, dicionario_girias_completo))

    if normalizar:
        texto = texto.apply(lambda x: normalizador.normalise(x))

    if substituir_emojis:
        texto = texto.apply(substitui_emoji)

    if converter_ascii:
        texto = texto.apply(lambda x: unidecode(x))

    if remover_pontuacao:
        texto = texto.apply(lambda x: re.sub(r'(?<!\d),(?=\D)|(?<=\D),(?!\d)|(?<!\d),(?=\d)|(?<!\d)\/|\/(?!\d)|_|[^\w#\/\s,\@]','', x))

    if tokenizar_texto:
        texto = texto.apply(tokenizar_e_limpar_texto)
        
    return texto
```



## 4. `pipeline_export(df, coluna, formato='json', **kwargs)`
Aplica o pr√©-processamento em uma coluna de um DataFrame e exporta os dados processados.

**Par√¢metros**:

- `df (pd.DataFrame)`: DataFrame original contendo os textos.
- `coluna (str)`: Nome da coluna que ser√° processada.
- `formato (str)`: Formato de exporta√ß√£o (json ou csv).
- `**kwargs`: Par√¢metros opcionais para as etapas de pr√©-processamento.

**Retorno**:

DataFrame original com uma nova coluna `texto_preprocessado`.


```python
def pipeline_export(df, coluna, formato='json', **kwargs):
    """
    Aplica o pr√©-processamento em uma coluna do DataFrame e exporta o DataFrame modificado.

    Par√¢metros:
    df (pd.DataFrame): O DataFrame original contendo os dados.
    coluna (str): Nome da coluna que ser√° processada.
    formato (str): Formato de exporta√ß√£o dos dados ('json' ou 'csv'). Padr√£o: 'json'.
    **kwargs: Par√¢metros opcionais para as etapas do pr√©-processamento.

    Retorna:
    pd.DataFrame: O DataFrame original com uma nova coluna chamada 'texto_preprocessado'.
    """

    df['texto_preprocessado'] = preprocess(df[coluna], **kwargs)

    # Exportar para o formato escolhido
    if formato == 'json':
        df.to_json('saida_preprocessada.json', orient='records', lines=True, force_ascii=False)
    elif formato == 'csv':
        df.to_csv('saida_preprocessada.csv', index=False)
    else:
        print(f"Formato {formato} n√£o √© suportado.")
    
    return df  # Retorna o DataFrame original com a nova coluna
```



## 5. `pipeline(caminho_arquivo, coluna, formato='csv', **kwargs)` 
Fun√ß√£o principal que aplica o pipeline ao arquivo fornecido e exporta o resultado.

**Par√¢metros**:

- `caminho_arquivo (str)`: Caminho do arquivo a ser processado (.csv ou .json).
- `coluna (str)`: Nome da coluna a ser processada.
- `formato (str)`: Formato de exporta√ß√£o (csv ou json).
- `**kwargs`: Par√¢metros opcionais para as etapas de pr√©-processamento.

**Retorno**:

Exibe o DataFrame modificado ap√≥s o processamento e exporta√ß√£o.

```python
def pipeline(caminho_arquivo, coluna, formato='csv', **kwargs):
    """
    Fun√ß√£o principal que aplica o pipeline de pr√©-processamento ao arquivo fornecido.

    Par√¢metros:
    caminho_arquivo (str): Caminho para o arquivo a ser processado (.csv ou .json).
    coluna (str): Nome da coluna que ser√° processada no DataFrame.
    formato (str): Formato de exporta√ß√£o dos dados ('json' ou 'csv'). Padr√£o: 'csv'.
    **kwargs: Par√¢metros opcionais para as etapas do pr√©-processamento.

    Retorna:
    None: Exibe o DataFrame modificado ap√≥s o processamento e exporta√ß√£o.
    """

    # Verificar a extens√£o do arquivo para carregar o DataFrame corretamente
    if caminho_arquivo.endswith('.csv'):
        df = pd.read_csv(caminho_arquivo)
    elif caminho_arquivo.endswith('.json'):
        df = pd.read_json(caminho_arquivo, lines=True)
    else:
        raise ValueError("Formato de arquivo n√£o suportado. Use um arquivo .csv ou .json")
    
    # Aplicar o pipeline e exportar
    df_modificado = pipeline_export(df, coluna, formato, **kwargs)
    
    # Exibir o DataFrame modificado
    print(df_modificado)
```

# Estrutura de Sa√≠da
O pipeline cria uma nova coluna chamada texto_preprocessado no DataFrame original e exporta o resultado em um dos seguintes formatos:

- `JSON`
- `CSV`

Para escolher o formato de sa√≠da, utilize o par√¢metro `formato` ao chamar a fun√ß√£o `pipeline` ou `pipeline_export`. Defina `formato='json'` para exportar como JSON ou `formato='csv'` para CSV.

```python
from pipeline import pipeline

# Executa o pipeline e exporta o resultado em formato CSV
pipeline('dados.csv', 'texto', formato='csv')
```


# Detalhes do Pr√©-processamento de Texto
## 1. Substitui√ß√£o de usu√°rios (substituir_users)

Substitui men√ß√µes a usu√°rios no formato @usuario por um placeholder <user>. Fazer isso antes de normalizar evita que o normalizador altere os padr√µes @ e quebras na regex.

```python
if substituir_users:
    texto = texto.str.replace(r'@\w+', '<user>', regex=True)
```

Exemplo
Entrada: ["@joao gostei", "obrigado @maria!"]
Sa√≠da: ["<user> gostei", "obrigado <user>!"]

## 2. Substitui√ß√£o de URLs (remover_urls)

Substitui URLs por um placeholder <hyperlink> ‚Äî feito cedo para evitar que normalizadores ou substitui√ß√µes subsequentes quebrem os links.

```python
if remover_urls:
    texto = texto.apply(lambda x: re.sub(r'http\S+', '<hyperlink>', x))
```

Exemplo
Entrada: ["veja http://ex.com", "link: https://site.com/test"]
Sa√≠da: ["veja <hyperlink>", "link: <hyperlink>"]

## 3. Substitui√ß√£o de g√≠rias (substituir_girias)

Aplica o dicion√°rio de g√≠rias, substituindo apenas palavras inteiras (uso de \b), e usa ordena√ß√£o por tamanho para evitar colis√µes (ex.: pq vs p).

```python
texto = texto.apply(lambda x: substituir_girias(x, dicionario_girias_completo))
```

Exemplo
Entrada: "vc ta mt loko hj"
Sa√≠da: "voc√™ ta muito louco hoje"

## 4. Normaliza√ß√£o Enelvo (normalizar)

Aplica o normalizador.normalise(x) da biblioteca Enelvo para corrigir grafias, abrevia√ß√µes e varia√ß√µes coloquiais. Normaliza√ß√£o vem ap√≥s users/URLs/g√≠rias para n√£o atrapalhar placeholders.

```python
if normalizar:
    texto = texto.apply(lambda x: normalizador.normalise(x))
```

Exemplo
Entrada: "testeee q q rolou"
Sa√≠da: "teste que que rolou" (exemplo ilustrativo)

## 5. Substitui√ß√£o de emojis (substituir_emojis)

Substitui emojis por r√≥tulos/descritivos (usa emoji_list + demoji), transformando s√≠mbolos em tokens textuais significativos.

```python
if substituir_emojis:
    texto = texto.apply(substitui_emoji)
```

Exemplo
Entrada: ["üòÄ que delicia", "t√¥ triste üò¢"]
Sa√≠da: ["emoji_feliz que delicia", "t√¥ triste emoji_triste"]

## 6. Convers√£o para ASCII (converter_ascii)

Converte caracteres acentuados e especiais para representa√ß√µes ASCII com unidecode, evitando inconsist√™ncias entre acentuados e n√£o acentuados.

```python
if converter_ascii:
    texto = texto.apply(lambda x: unidecode(x))
```

Exemplo
Entrada: "voc√™ est√° √≥timo"
Sa√≠da: "voce esta otimo"

## 7. Remo√ß√£o de pontua√ß√£o e caracteres indesejados (remover_pontuacao)

Aplica express√£o regular que remove pontua√ß√µes e s√≠mbolos indesejados, mas tenta preservar hashtags, n√∫meros relevantes e outros padr√µes esperados pelo seu pipeline (conforme a regex utilizada no c√≥digo).

```python
if remover_pontuacao:
    texto = texto.apply(lambda x: re.sub(r'(?<!\d),(?=\D)|(?<=\D),(?!\d)|(?<!\d),(?=\d)|(?<!\d)\/|\/(?!\d)|_|[^\w#\/\s,\@]','', x))
```

Exemplo
Entrada: "Ol√°!!! T√°, 100% (teste) ~"
Sa√≠da: "Ol√° T√° 100 teste "

## 8. Tokeniza√ß√£o e limpeza final (tokenizar_texto)

Se ativada, a fun√ß√£o tokenizar_e_limpar_texto √© aplicada ‚Äî geralmente faz tokeniza√ß√£o (por NLTK ou split), remo√ß√£o de stopwords, limpeza de tokens vazios e possivelmente lematiza√ß√£o/stem (depende da implementa√ß√£o interna dessa fun√ß√£o).

```python
if tokenizar_texto:
    texto = texto.apply(tokenizar_e_limpar_texto)
```

Exemplo
Entrada (ap√≥s limpezas): "este √© um texto de teste"
Sa√≠da: ["texto", "teste"] (exemplo ilustrativo ‚Äî formato pode ser lista de tokens ou string, dependendo da fun√ß√£o)

---

## Diagrama do Processo

![Diagrama do Pipeline](assets/diagrama.png)

---

## Observa√ß√µes

- Pode ser adaptado para outros idiomas ajustando as stopwords e o mapeamento de g√≠rias.  
- Ideal para **an√°lises de sentimento**, **classifica√ß√£o de textos** e **limpeza de bases lingu√≠sticas**.

---

## Teste


---

## Autor

Desenvolvido por **Jo√£o Pedro Honorato**  
